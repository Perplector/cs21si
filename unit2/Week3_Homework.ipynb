{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Accidentally) Racist Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x, y = np.load('resources/X.npy'), np.load('resources/y.npy')\n",
    "indexes = list(np.load('resources/indexes.npy'))\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're going to use the simple intuition behind word2vec to create our own word vectors--and discover how easy it is to make something horrifying on accident. Our training data is vector representations of an article on crime and race from Wikipedia, a seemingly unbiased source. Here's the link: https://en.wikipedia.org/wiki/Race_and_crime_in_the_United_States\n",
    "\n",
    "## Forward and Backward Passes\n",
    "\n",
    "Write the code below for the forward pass (made of two fully-connected layers and a softmax-cross-entropy layer) and the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_cache = {}\n",
    "def forward_pass(x, y, W1, W2):\n",
    "    h = None\n",
    "    y_hat = None\n",
    "\n",
    "    softmax = None\n",
    "    losses = None\n",
    "    loss = None\n",
    "    \n",
    "    forward_cache['x'], forward_cache['y'], forward_cache['y_hat'] = x, y, y_hat\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass():\n",
    "    x, y, y_hat = forward_cache['x'], forward_cache['y'], forward_cache['y_hat']\n",
    "    \n",
    "    dSCE = None\n",
    "    \n",
    "    dW1 = None\n",
    "    dW2 = None\n",
    "    \n",
    "    return dW1, dW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We have written the training script for you below. Run it to train the model for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = x.shape[1], 70\n",
    "batch_size = 2\n",
    "\n",
    "W1 = np.random.randn(N, D)\n",
    "W2 = np.random.randn(D, N)\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    batch, target = x[i:i+batch_size], y[i:i+batch_size]\n",
    "    loss = forward_pass(batch, target, W1, W2)\n",
    "    dW1, dW2 = backward_pass()\n",
    "\n",
    "    W1 -= 1e-2 * dW1\n",
    "    W2 -= 1e-2 * dW2\n",
    "        \n",
    "    if i % 400 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation\n",
    "\n",
    "Now it's time to see what monster we've created. Run the code below to see the horrifying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word):\n",
    "    return W1[indexes.index(word)]\n",
    "\n",
    "def cosine_sim(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "def evaluate_adjective(adj):\n",
    "    groups = ['white', 'black', 'hispanic', 'asian']\n",
    "    evaluation = [(cosine_sim(word2vec(adj), word2vec(group)), group) for group in groups]\n",
    "    evaluation = sorted(evaluation, reverse=True)\n",
    "    \n",
    "    ranks = ['most', 'second most', 'third most', 'least']\n",
    "    for i, ranking in enumerate(evaluation):\n",
    "        print('%s is %s %s group' % (ranking[1], ranks[i], adj))\n",
    "    \n",
    "evaluate_adjective('illegal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! This is awful!\n",
    "\n",
    "The biggest lesson to learn out of all of this: even those with good intentions can make something bad with AI. You are not a bad person--but you've made a bad AI system that can have terrible ramifications. You *must* keep this in mind as you develop AI systems in the real world in the near future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
